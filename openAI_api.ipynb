{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yeongchae-Shim/Bankruptcy-prediction/blob/master/openAI_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pz1UqGEV9h1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c28065d-1696-4562-f6b1-f8843ca715e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m681.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok xgboost tensorflow scikit-learn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Streamlit ì•± ì½”ë“œ ì €ìž¥\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from pyngrok import ngrok\n",
        "\n",
        "st.set_page_config(page_title=\"VaR Prediction Dashboard\", layout=\"centered\")\n",
        "\n",
        "st.title(\"ðŸ“‰ Portfolio VaR Predictor\")\n",
        "st.markdown(\"This dashboard predicts 1-day Value at Risk (VaR) using XGBoost and ANN.\")\n",
        "\n",
        "# Sample input\n",
        "st.sidebar.header(\"Portfolio Input (Daily Returns)\")\n",
        "portfolio_input = st.sidebar.text_area(\"Enter comma-separated returns (e.g., -0.01, 0.02, -0.03)\", \"-0.01, 0.02, -0.03, 0.01, -0.015, 0.005\")\n",
        "\n",
        "try:\n",
        "    returns = np.array([float(x) for x in portfolio_input.split(\",\")])\n",
        "    returns = returns.reshape(-1, 1)\n",
        "except:\n",
        "    st.error(\"âŒ Invalid input format. Please check your returns.\")\n",
        "    st.stop()\n",
        "\n",
        "# Prepare features\n",
        "df = pd.DataFrame(returns, columns=['Return'])\n",
        "df['Lag1'] = df['Return'].shift(1)\n",
        "df['Lag2'] = df['Return'].shift(2)\n",
        "df['Lag3'] = df['Return'].shift(3)\n",
        "df['MA_3'] = df['Return'].rolling(3).mean()\n",
        "df['Vol_3'] = df['Return'].rolling(3).std()\n",
        "df['Target'] = df['Return'].shift(-1)  # next-day return\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "X = df[['Lag1', 'Lag2', 'Lag3', 'MA_3', 'Vol_3']]\n",
        "y = df['Target']\n",
        "\n",
        "# Split for simple test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- XGBoost ---\n",
        "xgb_model = XGBRegressor(n_estimators=100, max_depth=3)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "xgb_var = np.percentile(xgb_pred, 5)\n",
        "\n",
        "# --- ANN ---\n",
        "ann_model = Sequential([\n",
        "    Dense(32, input_shape=(X.shape[1],), activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "ann_model.compile(optimizer='adam', loss='mse')\n",
        "ann_model.fit(X_train, y_train, epochs=50, verbose=0)\n",
        "ann_pred = ann_model.predict(X_test).flatten()\n",
        "ann_var = np.percentile(ann_pred, 5)\n",
        "\n",
        "st.metric(\"ðŸ”º XGBoost VaR (95%)\", f\"{xgb_var:.2%}\")\n",
        "st.metric(\"ðŸ”· ANN VaR (95%)\", f\"{ann_var:.2%}\")\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "ax.hist(xgb_pred, bins=30, alpha=0.5, label='XGBoost')\n",
        "ax.hist(ann_pred, bins=30, alpha=0.5, label='ANN')\n",
        "ax.axvline(xgb_var, color='red', linestyle='--', label=f'XGB VaR: {xgb_var:.2%}')\n",
        "ax.axvline(ann_var, color='blue', linestyle='--', label=f'ANN VaR: {ann_var:.2%}')\n",
        "ax.set_title(\"Predicted Return Distribution\")\n",
        "ax.legend()\n",
        "st.pyplot(fig)"
      ],
      "metadata": {
        "id": "YoA224XW91uC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d9fd05-98ff-43e3-d49a-9d0d90380233"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT"
      ],
      "metadata": {
        "id": "HRiUOwlAOeYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Chat Completion"
      ],
      "metadata": {
        "id": "zyKMw_WfMsgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = openai.ChatCompletion.create(\n",
        "  model = \"gpt-3.5-turbo\",                             # ëª¨ë¸ëª… (í•„ìˆ˜)\n",
        "  messages = [{\"role\": \"user\", \"content\": \"ë‚œ ë­˜ í•˜ê³  ì‚´ë©´ ì¢‹ì„ê¹Œ?\"}],\n",
        "                                                       # ë©”ì„¸ì§€ ë¦¬ìŠ¤íŠ¸ (í•„ìˆ˜ but \"name\") {\"role\": system/user/assistant, \"content\": ë©”ì‹œì§€ ë‚´ìš©, \"name\": ì´ë¦„}\n",
        "  temperature = 1,                                     # output randomness [0~2] 0.2 small 0.8 big (either this or top_n, not both)\n",
        "  # top_p = 1,                                         # probability considered [0~1]\n",
        "  n = 1,                                               # N of chat completion choices\n",
        "  stream = False,                                      # streaming\n",
        "  # stop = ['.'],                                      # token ìƒì„±ì„ ë©ˆì¶”ê²Œ í•˜ëŠ” ì¡°ê±´ sequences(4ê°œê¹Œì§€)\n",
        "  max_tokens = 200,                                    # ìµœëŒ€ token ìˆ˜\n",
        "  presence_penalty = 0,                                # ìƒˆë¡œìš´ í† í”½ì„ ë§í•  í™•ë¥ ì„ ë†’ì—¬ì£¼ëŠ” [-2~2]\n",
        "  frequency_penalty = 0,                               # ë˜‘ê°™ì€ ë¬¸ìž¥ì„ ë§í•  í™•ë¥ ì„ ë‚®ì¶°ì£¼ëŠ” [-2~2]\n",
        "  logit_bias = {},                                     # íŠ¹ì • í† í°ë“¤ì˜ ì¶œí˜„ í™•ë¥ ì„ ìˆ˜ì •\n",
        "  user = '',                                           # openAI ëª¨ë‹ˆí„°ìš© ID\n",
        ")\n",
        "print(chat)"
      ],
      "metadata": {
        "id": "vtkhh_sk7nYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat[\"choices\"][1][\"message\"][\"content\"])"
      ],
      "metadata": {
        "id": "sE3gzj327qHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Whisper"
      ],
      "metadata": {
        "id": "2H7rlCNEOaWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2023Spring/main/test.wav\"\n",
        "os.system(\"curl \" + url + \" > test.wav\")"
      ],
      "metadata": {
        "id": "2q-Wsv31M8ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Transcript"
      ],
      "metadata": {
        "id": "XI2k0kwcWEII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = open(\"test.wav\", \"rb\")\n",
        "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "print(transcript)"
      ],
      "metadata": {
        "id": "K-nkFpHl91il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transcript['text'])"
      ],
      "metadata": {
        "id": "89zz8dCIUUH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Translation"
      ],
      "metadata": {
        "id": "lSSHteUkPxPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = open(\"test.wav\", \"rb\")\n",
        "translation = openai.Audio.translate(\"whisper-1\", audio_file)\n",
        "print(translation)"
      ],
      "metadata": {
        "id": "AjoroAZULJX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(translation['text'])"
      ],
      "metadata": {
        "id": "Po9AaqcIUWYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DALLÂ·E 2"
      ],
      "metadata": {
        "id": "9ZMGGpkqSNin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Image"
      ],
      "metadata": {
        "id": "bPrq_BmySoLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = openai.Image.create(\n",
        "  prompt=\"cat and dog\",\n",
        "  n=1,\n",
        "  size=\"512x512\"\n",
        ")\n",
        "print(image)"
      ],
      "metadata": {
        "id": "2Ge80K2kTPrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Image Edit"
      ],
      "metadata": {
        "id": "fKjInh6TTVos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2023Spring/main/original.png\"\n",
        "os.system(\"curl \" + url + \" > original.png\")\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2023Spring/main/mask.png\"\n",
        "os.system(\"curl \" + url + \" > mask.png\")"
      ],
      "metadata": {
        "id": "Rp3XLSJkd-qL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = openai.Image.create_edit(\n",
        "  image=open(\"original.png\", \"rb\"),\n",
        "  mask=open(\"mask.png\", \"rb\"),\n",
        "  prompt=\"a greedy pig whose tongue is snake-like without the masked area\",\n",
        "  n=1,\n",
        "  size=\"512x512\"\n",
        ")\n",
        "print(image)"
      ],
      "metadata": {
        "id": "yO9_qWQ3S1Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Image Variation"
      ],
      "metadata": {
        "id": "OwHmP2zEegbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2023Spring/main/cat_dot.png\"\n",
        "os.system(\"curl \" + url + \" > cat_dot.png\")"
      ],
      "metadata": {
        "id": "xsCTgu4YemM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = openai.Image.create_variation(\n",
        "  image=open(\"cat_dot.png\", \"rb\"),\n",
        "  n=1,\n",
        "  size=\"512x512\"\n",
        ")\n",
        "print(image)"
      ],
      "metadata": {
        "id": "DY4cafkUfIzf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}